# DecisionTree

This is a decision tree that returns the best attribute split for continuous variables where a smaller attribute index is given preference for splitting. The maximum depth is set to 2.

Steps:
1. Open DecisionTreeNB
2. Go to bottom cell and select dataset from range: f-i and pass it to read_data function
3. Select the corresponding data labels by passing same value + 1: ex: read_data(f), read_ans(f1)
4. Run all cells and view results with CPU times
5. Optional: Import you own data in the given format and run!
